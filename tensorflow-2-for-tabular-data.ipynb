{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["### This notebook describes how to stack a Tensorflow 2 simple model for tabular data binary calssification.\n","\n","It is part of my solution of the TPS competition in. It will train the same model on different data spilits and then combine the \n","out of folds (oofs) in another level using a simple linear regression.\n","\n","There are four main components in this notebook used here: **experiment**, **model**, **level**, and **stack**. These will be modeled by classes as described in this notebook."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["#!pip install -q -U tensorflow_addons"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:14:12.283149Z","iopub.execute_input":"2021-09-29T17:14:12.283556Z","iopub.status.idle":"2021-09-29T17:14:12.28872Z","shell.execute_reply.started":"2021-09-29T17:14:12.283457Z","shell.execute_reply":"2021-09-29T17:14:12.288074Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# Familiar imports\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from IPython.display import display\n","\n","import os\n","import gc\n","import glob\n","import random\n","from datetime import datetime\n","from pathlib import Path\n","\n","\n","\n","# helpers\n","from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder, PowerTransformer, StandardScaler, \\\n","                                  MinMaxScaler, RobustScaler, PolynomialFeatures, QuantileTransformer,  KBinsDiscretizer\n","\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold\n","from sklearn.pipeline import make_pipeline, Pipeline\n","\n","\n","\n","# Models\n","from sklearn.linear_model import LogisticRegression\n","\n","\n","# TF2\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Input, Dense, Conv1D,   Dropout,  Concatenate, Embedding,  Flatten, Add, Average\n","from tensorflow.keras.models import Model\n","\n","from tensorflow import keras\n","import tensorflow_addons as tfa\n","\n","\n","# base\n","from sklearn.base import clone\n","\n","# scoring\n","from sklearn import metrics"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:14:12.290225Z","iopub.execute_input":"2021-09-29T17:14:12.291006Z","iopub.status.idle":"2021-09-29T17:14:18.915778Z","shell.execute_reply.started":"2021-09-29T17:14:12.290973Z","shell.execute_reply":"2021-09-29T17:14:18.914922Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# notebook options\n","pd.set_option(\"display.max_columns\", 100)\n","path = \"../input/tabular-playground-series-sep-2021/\"\n","train_file = \"train.csv\"\n","test_file = \"test.csv\"\n","\n","# tpu\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Device:', tpu.master())\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","except:\n","    strategy = tf.distribute.get_strategy()\n","print('Number of replicas:', strategy.num_replicas_in_sync)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:14:18.917201Z","iopub.execute_input":"2021-09-29T17:14:18.917473Z","iopub.status.idle":"2021-09-29T17:14:18.93154Z","shell.execute_reply.started":"2021-09-29T17:14:18.917444Z","shell.execute_reply":"2021-09-29T17:14:18.93035Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# Load the training data\n","train = pd.read_csv(f'{path}{os.sep}{train_file}', index_col=0)\n","test = pd.read_csv(f'{path}{os.sep}{test_file}', index_col=0)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:14:18.934595Z","iopub.execute_input":"2021-09-29T17:14:18.935Z","iopub.status.idle":"2021-09-29T17:15:02.740574Z","shell.execute_reply.started":"2021-09-29T17:14:18.934948Z","shell.execute_reply":"2021-09-29T17:15:02.739694Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["print(f'Train set size {train.memory_usage(index=False).sum()/(2**30)}')\n","print(f'Test set size {test.memory_usage(index=False).sum()/(2**30)}')"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:02.743787Z","iopub.execute_input":"2021-09-29T17:15:02.744537Z","iopub.status.idle":"2021-09-29T17:15:02.764902Z","shell.execute_reply.started":"2021-09-29T17:15:02.744492Z","shell.execute_reply":"2021-09-29T17:15:02.764224Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# Separate target from features\n","y = train['claim']\n","X = train.drop(['claim'], axis=1)\n"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:02.766261Z","iopub.execute_input":"2021-09-29T17:15:02.766935Z","iopub.status.idle":"2021-09-29T17:15:03.099099Z","shell.execute_reply.started":"2021-09-29T17:15:02.766887Z","shell.execute_reply":"2021-09-29T17:15:03.09842Z"},"trusted":true}},{"cell_type":"markdown","source":["### Feature Engineering"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["\n","# identify columns\n","numerical_cols = list(X.select_dtypes(include=np.number).columns)\n","non_numeric_cols = list(X.select_dtypes(include=['object', 'bool']).columns)\n","\n","print(f'We have {len(numerical_cols)} numeric and {len(non_numeric_cols)} non-numeric features')\n","\n","\n","# work on a copy\n","X_train = X.copy()\n","X_test = test.copy()\n","\n","\n","# all features\n","features = non_numeric_cols + numerical_cols\n","\n","# new features\n","# https://www.kaggle.com/hiro5299834/tps-sep-2021-single-lgbm\n","X_train['n_missing'] = X_train[features].isna().sum(axis=1)\n","X_test['n_missing'] = X_test[features].isna().sum(axis=1)\n","\n","X_train['std'] = X_train[features].std(axis=1)\n","X_test['std'] = X_test[features].std(axis=1)\n","\n","\n","\n","features += ['n_missing', 'std']\n","\n","# imputation\n","X_train[features] = X_train[features].fillna(X_train[features].mean())\n","X_test[features] = X_test[features].fillna(X_test[features].mean())\n","\n","\n","\n","\n","# useful for column transformers \n","numerical_ix = X_train.columns.get_indexer(features)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:03.100564Z","iopub.execute_input":"2021-09-29T17:15:03.101069Z","iopub.status.idle":"2021-09-29T17:15:10.411713Z","shell.execute_reply.started":"2021-09-29T17:15:03.101027Z","shell.execute_reply":"2021-09-29T17:15:10.410484Z"},"trusted":true}},{"cell_type":"markdown","source":["### Model-dev helper functions\n","\n","These are functions to save and load predictions, they can be wrapped within a class for a better modeling or kept as they are since they are independent of the project setting.\n"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["\n","## helper fucntions\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","\n","\n","\n","        \n","def to_file(data, output_folder, idxs=None, suffix='.csv'):\n","    print(data)\n","    df = pd.DataFrame(data)\n","    df.to_csv(f'{output_folder}{os.sep}{suffix}', index=True)\n","        \n","    \n","def calc_folds_indexes(X, y, n_folds=5, shuffle=True, sampler=KFold, seeds=[42]):\n","    \"\"\"\n","    Create folds from a dataset X and a target y\n","    sampler: can be KFold,  StratifiedKFold, or any sampling class  \n","    \n","    return a list of dictionaries of {'seed':, 'idxs':[train_idxs, test_idxs]}\n","    \"\"\"\n","    folds_idxs_list = []\n","    for seed in seeds:\n","        folds = sampler(n_splits=n_folds, \n","                        random_state=seed,\n","                        shuffle=shuffle)\n","\n","        folds_idxs_list.append({'seed': seed, 'idxs':list(folds.split(X, y))})\n","        \n","    return folds_idxs_list   \n","\n","def score(y, target, average=False):\n","    # if y is a list then it will return a list of scores\n","    # if average is True then it will return the mean of the scores\n","    \n","    if type(y) in [list, np.ndarray]:\n","        scores = []\n","        for y_i in y:\n","            scores.append(score_func(y_i, target, **score_func_params))\n","        if average:\n","            return np.mean(scores)\n","        else:\n","            return scores\n","        \n","    return score_func(y, target, **score_func_param)\n"],"outputs":[],"metadata":{"code_folding":[],"execution":{"iopub.status.busy":"2021-09-29T17:15:10.412933Z","iopub.execute_input":"2021-09-29T17:15:10.41317Z","iopub.status.idle":"2021-09-29T17:15:10.424108Z","shell.execute_reply.started":"2021-09-29T17:15:10.413143Z","shell.execute_reply":"2021-09-29T17:15:10.423468Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# initialize things\n","\n","# seed\n","seed = 42\n","seed_everything(seed)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:10.425127Z","iopub.execute_input":"2021-09-29T17:15:10.425948Z","iopub.status.idle":"2021-09-29T17:15:10.443791Z","shell.execute_reply.started":"2021-09-29T17:15:10.425905Z","shell.execute_reply":"2021-09-29T17:15:10.442763Z"},"trusted":true}},{"cell_type":"markdown","source":["### ModelWrapper \n","This main role of this class is to avoid coding multiple classes for each model (or model types). We can see that models can actually be categorized into different categories, where some models accept more parameters than the others. For instance xgboost can use an evaluation set to determine the stopping round number, while Lasso does not have such extra parameters.\n","\n","Thanks to the flexibility of Python and the design of the base models, we can wrap the model and develope a `wrapper` to do what the model should do. In fact, we can easily stretch this class to support sklearn pipelines or any framework we are using. The idea is again, seperate code from data and try to generalize.\n"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["class ModelWrapper():\n","    def __init__(self, \n","                 model,\n","                 name,\n","                 main_params,\n","                 uses_eval_set=False,\n","                 fit_params={}):\n","        \n","        self.model = model\n","        self.name = name\n","        self.main_params = main_params\n","        self.uses_eval_set = uses_eval_set\n","        self.fit_params = fit_params # any extra params for the 'fit' function\n","                \n","    def create_model(self, random_state=None):\n","        \"\"\"\n","        create a model \n","        \"\"\"\n","        model = self.model(**self.main_params)\n","        if random_state is not None:\n","            if hasattr(model, 'random_state'):\n","                model.random_state = random_state\n","            elif hasattr(model, 'random_seed'):\n","                model.random_seed = random_state\n","        \n","        return model\n","    \n","        "],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:10.446643Z","iopub.execute_input":"2021-09-29T17:15:10.447477Z","iopub.status.idle":"2021-09-29T17:15:10.459792Z","shell.execute_reply.started":"2021-09-29T17:15:10.447423Z","shell.execute_reply":"2021-09-29T17:15:10.458749Z"},"trusted":true}},{"cell_type":"markdown","source":["### ModelTrainer\n","This role of this class is to train a model and calculate the oofs and the test predictions (meta-features). That is, to cross validate.\n"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["class ModelTrainer():\n","    def __init__(self,\n","                  model_wrapper: ModelWrapper):\n","        \n","        self.modelwrapper = model_wrapper\n","        \n","    def cross_validate(self,\n","                  X, y,\n","                  X_test,\n","                  folds_idxs,\n","                  transformer=None,\n","                  fit_transform_on_test_set=False,\n","                  verbose=False,\n","                  use_different_random_states=True, \n","                  score_function=metrics.roc_auc_score,\n","                  score_function_params={}):\n","        \"\"\"\n","        Return the oofs predictions and the meta features (test predictions)\n","        \"\"\"\n","        \n","        test_predictions = 0\n","        oof_predictions = np.zeros_like(np.array(y), dtype=np.float64)\n","        valid_mean_score = [] \n","        for fold, (train_ix, valid_ix) in enumerate(folds_idxs): # we are not using spilit here for a better generalization\n","            X_train, X_valid = X[train_ix], X[valid_ix]\n","            y_train, y_valid = y[train_ix], y[valid_ix]\n","                             \n","            # transform input\n","            if transformer is not None:\n","                X_train = transformer.fit_transform(X_train)\n","                if fit_transform_on_test_set:\n","                    X_valid = transformer.fit_transform(X_valid)\n","                    X_test_ = transformer.fit_transform(X_test)\n","                else:\n","                    X_test_ = transformer.transform(X_test)\n","                    X_valid = transformer.transform(X_valid)\n","            else:\n","                X_test_ = X_test\n","                \n","            # check if we train each fold on differently initialized clone\n","            if use_different_random_states:\n","                model = self.modelwrapper.create_model(random_state=fold)\n","            else:\n","                model = self.modelwrapper.create_model()\n","            \n","            # fit the model\n","            if self.modelwrapper.uses_eval_set:\n","                model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], **self.modelwrapper.fit_params)\n","            else:\n","                model.fit(X_train, y_train, **self.modelwrapper.fit_params)\n","                \n","            ## predictions\n","            # on the validation set\n","            valid_predications = model.predict_proba(X_valid)[:, -1]\n","            score = score_function(y_valid, valid_predications)\n","            valid_mean_score.append(score)\n","            oof_predictions[valid_ix] = valid_predications\n","            \n","            # on the test set        \n","            test_predictions += model.predict_proba(X_test_)[:, -1] / len(folds_idxs)\n","            \n","            if verbose:\n","                print('Model:{} Fold:{} score:{:.4f}'.format(self.modelwrapper.name, fold + 1, score))\n","        \n","        if verbose:\n","            print('Average score:{:.4f} ({:.4f})'.format(np.mean(valid_mean_score), np.std(valid_mean_score) ))\n","    \n","        return oof_predictions, test_predictions"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:10.461535Z","iopub.execute_input":"2021-09-29T17:15:10.461789Z","iopub.status.idle":"2021-09-29T17:15:10.483105Z","shell.execute_reply.started":"2021-09-29T17:15:10.46176Z","shell.execute_reply":"2021-09-29T17:15:10.481966Z"},"trusted":true}},{"cell_type":"markdown","source":["### Level\n","The level class glues all components in a given layer"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["class Level():\n","    def __init__(self,\n","                level_id,\n","                models,\n","                folder,\n","                transformer,\n","                n_folds=5,\n","                seeds=[42],\n","                frozen=False,\n","                fit_transform_on_test_set = False,\n","                use_different_random_states=True):\n","        \n","        self.level_id = level_id\n","        self.models = models\n","        self.folder = folder\n","        self.transformer = transformer\n","        self.n_folds = n_folds\n","        self.seeds = seeds\n","        self.frozen = frozen=False\n","        self.fit_transform_on_test_set = fit_transform_on_test_set\n","        self.use_different_random_states = use_different_random_states\n","    \n","    def create(self, model_zoo):\n","        \"\"\"\n","         Create a level.\n","         model_zoo: a dictionay of all avialable models.\n","        \"\"\"\n","        self.model_wrappers = []\n","        \n","        # get models \n","        # if models is set to 'all' use all models\n","        if self.models[0].lower() == 'all':\n","            level_models_names = model_zoo.keys()\n","        else: \n","            level_models_names = self.models\n","\n","        for model_name in level_models_names:\n","            # get paramaters  \n","            model_dict = model_zoo[model_name]\n","            model = model_dict['model']\n","            fit_kwargs = model_dict['fit_kwargs']\n","            app_params = model_dict['app_params']\n","            main_params = model_dict['main_params']\n","\n","            model_wrapper = ModelWrapper(model=model, name=model_name, main_params=main_params)\n","            if fit_kwargs is not None:\n","                model_wrapper.fit_params = fit_kwargs\n","            if app_params is not None:\n","                model_wrapper.uses_eval_set = app_params['uses_eval_set']\n","            self.model_wrappers.append(model_wrapper)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:10.484546Z","iopub.execute_input":"2021-09-29T17:15:10.485245Z","iopub.status.idle":"2021-09-29T17:15:10.502651Z","shell.execute_reply.started":"2021-09-29T17:15:10.485198Z","shell.execute_reply":"2021-09-29T17:15:10.50193Z"},"trusted":true}},{"cell_type":"markdown","source":["#### Level Trainer\n","Trains all models in a given level."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["class LevelTrainer():\n","    def __init__(self,\n","                level,\n","                seeds_folds_idxs_list):\n","        self.level = level\n","        self.seeds_folds_idxs_list = seeds_folds_idxs_list\n","        \n","    def train(self, X_train, y, X_test, verbose=True, agg_func=None):\n","        \"\"\"\n","        train the level and return the oofs and meta-features for each model in the level.\n","        If the level has many seeds it will either use the agg_func to combine predictions\n","        or will just return eveything, it depends on agg_func\n","        \n","        agg_func: can be None, np.mean, or any other numpy reduction function\n","        \"\"\"\n","\n","        level_oof_preds, level_test_preds = {}, {}\n","        for model_wrapper in self.level.model_wrappers:\n","            if verbose:\n","                print('-'*30)\n","                print(f'Model:{model_wrapper.name}')\n","                print('-'*30)\n","\n","            # train each model with as many times as the length of folds_idxs_list \n","            model_oof_preds, model_test_preds = [], []\n","            \n","            for seeds_folds_idxs in self.seeds_folds_idxs_list:\n","                seed, folds_idxs = seeds_folds_idxs['seed'], seeds_folds_idxs['idxs']\n","                print('-'*30)\n","                print(f'Seed:{seed}')\n","                print('-'*30)\n","                \n","                trainer = ModelTrainer(model_wrapper)\n","                oof_preds, test_preds = trainer.cross_validate(X_train, \n","                                                          y,\n","                                                          X_test,\n","                                                          transformer=self.level.transformer,\n","                                                          folds_idxs=folds_idxs,\n","                                                          verbose=verbose,\n","                                                          fit_transform_on_test_set=self.level.fit_transform_on_test_set)\n","                if agg_func is None:\n","                    level_oof_preds[f'{model_wrapper.name}_seed_{seed}'] =  oof_preds\n","                    level_test_preds[f'{model_wrapper.name}_seed_{seed}'] =  test_preds\n","                else: # collect them in order to aggregate them with the agg_func function\n","                    model_oof_preds.append(oof_preds)\n","                    model_test_preds.append(test_preds)\n","\n","          # aggregate the results\n","        if agg_func is not None:\n","            level_oof_preds[f'{model_wrapper.name}'] = agg_func(np.column_stack(model_oof_preds))\n","            level_test_preds[f'{model_wrapper.name}'] = agg_func(np.column_stack(model_test_preds))\n","\n","        if verbose:\n","            print('-'*30)\n","\n","        return pd.DataFrame(level_oof_preds), pd.DataFrame(level_test_preds)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:10.504354Z","iopub.execute_input":"2021-09-29T17:15:10.504876Z","iopub.status.idle":"2021-09-29T17:15:10.523544Z","shell.execute_reply.started":"2021-09-29T17:15:10.504815Z","shell.execute_reply":"2021-09-29T17:15:10.522435Z"},"trusted":true}},{"cell_type":"markdown","source":["### Experiment \n","Since in many cases everything boils down to stacking, the experiment class will handle the organization of the resulted files from the test: test and oofs predictions. Therefore, assuming the project has the following structure with a folder called **experiments** we can save our tests in this folder. This is what this class will do. This class is the entry point for any run (experiment) in the project. It reads the input and the settings and produces the output.\n","\n","```\n","    TPS_project\n","    │   README.md\n","    │\n","    └───notebooks\n","    │   ...\n","    │\n","    └───experiments\n","    │   │   \n","    │   │\n","    │   └───experiment_1   \n","    │   │   level_1_oofs.csv\n","    │   │   level_1_test.csv\n","    │   │   level_2_oofs.csv\n","    │   │   level_2_test.csv\n","    │   │   ...\n","    │   │   meta_level_oofs.csv\n","    │   │   meta_level_test.csv\n","    │   └───experiment_...\n","```\n","\n","\n",">The code that generated the results is important to save too, but that can be done easily by creating a new version of the notebook or copying notebook with the CV_LB results. If we are running it in a local machine without notebooks, we can create a small function to copy the code files to the experiment levels. On other words, to save the code and the results for each experiement for a better look up.\n","\n",">This class is so important when running notebooks in our computers. Since Kaggle has a nice notebook management system it saves outputs as well.\n","\n"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["class Experiment():\n","    def __init__(self,\n","                 title,\n","                 description,\n","                 stack,\n","                 model_zoo,\n","                 main_folder=os.getcwd()):\n","        \n","        self.title = title\n","        self.main_folder = main_folder\n","        self.stack = stack\n","        self.model_zoo = model_zoo\n","        self.description = description\n","        # create the main folder if it does not exist\n","        if not os.path.exists(f'{self.main_folder}'):\n","            os.makedirs(f'{self.main_folder}', exist_ok=True)\n","        \n","    def join_folder(self, folder=None):\n","         \"\"\"\n","         Join a folder and output where results will be saved.\n","         If 'folder' is None, it will create a folder\n","         with a time stamp.\n","         \"\"\"\n","\n","         # create time stamp and subfolder with the current time stamp\n","         if folder is not None: # if folder is specified\n","            self.output_folder = folder \n","            # create a folder if does not exit.\n","            folder_path = f'{self.main_folder}{os.sep}{self.output_folder}'\n","            if not os.path.exists(folder_path):\n","                os.makedirs(folder_path)                \n","         else: # create a folder with the time stamp\n","            time_stamp = datetime.now().isoformat(' ', 'seconds')\n","            self.output_folder = self.title + ' ' + time_stamp.replace(':', '-')\n","            # create and replace if it exits.\n","            Path(f'{self.main_folder}{os.sep}{self.output_folder}').mkdir(parents=True, exist_ok=True)\n","    \n","    \n","    def run(self, X_train, y, X_test, \n","            train_idxs,\n","            test_idxs,\n","            verbose=True, store=True):\n","        \n","        # run the stack\n","        for  level_params in self.stack:\n","            # create all models in the level\n","            level = Level(**level_params)\n","            level.create(self.model_zoo)\n","\n","            print('-'*50)\n","            print(f'Current Level: {level.level_id}')\n","            print('-'*50)\n","\n","            # join the level's output folder\n","            #self.join_folder(folder=level.folder)\n","\n","            # create folds indexes for the level\n","            seeds_folds_idxs_list = calc_folds_indexes(X=X_train,\n","                                                       y=y,\n","                                                       n_folds=level.n_folds,\n","                                                       sampler=StratifiedKFold,\n","                                                       seeds=level.seeds)\n","\n","            # train the level\n","            if not level.frozen:  # escape any trained level   \n","                level_trainer = LevelTrainer(level=level, \n","                                             seeds_folds_idxs_list=seeds_folds_idxs_list)\n","\n","                level_oof_preds, level_test_preds =  level_trainer.train(X_train=X_train,\n","                                                                         y=y,\n","                                                                         X_test=X_test)\n","                # store predictions?\n","                if store:\n","                    # oofs \n","                    level_oof_preds.to_csv(f'{self.main_folder}{os.sep}{self.output_folder}{os.sep}{level.level_id}_oofs.csv')\n","                    # test predictions\n","                    level_test_preds.to_csv(f'{self.main_folder}{os.sep}{self.output_folder}{os.sep}{level.level_id}_test.csv')\n","                    \n","                \n","                # update train and test \n","                X_train, X_test = level_oof_preds.values, level_test_preds.values\n","            else:\n","                print('This level is already trained')\n","                # load saved of this level and raise error\n","                fold_id = level.n_folds\n","                folder =f'{self.main_folder}{os.sep}{self.output_folder}'\n","                \n","                # new features \n","                level_oof_preds = pd.read_csv(f\"{folder}{os.sep}*{fold_id}_oofs.csv\")\n","                level_test_preds = pdf.read_csv(f\"{folder}{os.sep}*{fold_id}_test.csv\")\n","                \n","                X_train = level_oof_preds.values\n","                X_test = level_test_preds.values\n","                \n","            if verbose:\n","                display(level_oof_preds.head(10))\n","                display(level_test_preds.head(10))\n","                \n","        # return the last output from the last level\n","        return level_test_preds"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:10.525432Z","iopub.execute_input":"2021-09-29T17:15:10.52588Z","iopub.status.idle":"2021-09-29T17:15:10.546583Z","shell.execute_reply.started":"2021-09-29T17:15:10.525817Z","shell.execute_reply":"2021-09-29T17:15:10.545261Z"},"trusted":true}},{"cell_type":"markdown","source":["### DNN Models"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# TF net class\n","class Net(tf.keras.Model):\n","    def __init__(self, \n","                  input_size, \n","                  output_size=1, \n","                  embedding_layer=Embedding, # nn.Embedding, nn.Linear, nn.Conv1d, ...\n","                  embedding_size=64,\n","                  feature_size=32\n","                 ):\n","        super(Net, self).__init__()\n","        \n","        self.input_size = input_size\n","        self.embedding_size = embedding_size\n","        self.output_size= output_size\n","        self.feature_size = feature_size\n","        \n","        # layers\n","        \n","        self.embedding_layer = embedding_layer(input_dim=embedding_size, output_dim=feature_size)\n","        self.conv1d_1 = Conv1D(filters=10, kernel_size=1, activation='swish', input_shape=(input_size, feature_size))\n","        self.fc_1 = Dense(units=feature_size, activation='swish')\n","        self.dropout_1 = Dropout(0.4)\n","        self.fc_2 = Dense(units=int(feature_size/2), activation='swish')\n","        self.dropout_2 = Dropout(0.2)\n","        self.fc_out = Dense(units=self.output_size, activation='sigmoid')\n","        \n","        \n","    def call(self, X, training=False):\n","        X = self.embedding_layer(X)\n","        X = Flatten()(X)\n","        X = self.fc_1(X)\n","        X = self.dropout_1(X)\n","        X = self.fc_2(X)\n","        X = self.dropout_2(X)\n","        X = self.fc_out(X)\n","        \n","        return X"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:10.5482Z","iopub.execute_input":"2021-09-29T17:15:10.548985Z","iopub.status.idle":"2021-09-29T17:15:10.567299Z","shell.execute_reply.started":"2021-09-29T17:15:10.548937Z","shell.execute_reply":"2021-09-29T17:15:10.566109Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["class NetModel():\n","    def __init__(self,\n","                 net,\n","                 optimizer= keras.optimizers.Adam(learning_rate=1e-4),\n","                 loss=tf.keras.losses.BinaryCrossentropy(),\n","                 metrics=[tf.keras.metrics.AUC(name='auroc')],\n","                 callbacks=None,\n","                 batch_size=1024,\n","                 epochs = 15,\n","                 device='gpu'):\n","        \n","        self.net = Net(**net_params)\n","        self.optimizer = optimizer\n","        self.loss = loss\n","        self.metrics = metrics\n","        self.batch_size = batch_size\n","        self.callbacks = callbacks\n","        self.epochs = epochs\n","        self.device = device\n","                \n","        \n","    def fit(self, X, y, eval_set=None):\n","        \n","        tf.keras.backend.clear_session()\n","            \n","        n_batches = len(X) // self.batch_size\n","        # set up scheduler and optimizer\n","       \n","        self.net.compile(loss=self.loss,\n","                        optimizer=self.optimizer,\n","                        metrics=self.metrics)\n","        \n","        if eval_set is None:\n","            self.net.fit(X, y, \n","                         batch_size=self.batch_size,\n","                        epochs=self.epochs,\n","                        callbacks=self.callbacks)\n","            \n","        else:\n","            self.net.fit(X, y, validation_data=eval_set[0], \n","                         batch_size=self.batch_size,\n","                        epochs=self.epochs,\n","                        callbacks=self.callbacks)\n","            \n","    def predict_proba(self, X):\n","        return self.net.predict(X)\n"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:10.56859Z","iopub.execute_input":"2021-09-29T17:15:10.568871Z","iopub.status.idle":"2021-09-29T17:15:10.635175Z","shell.execute_reply.started":"2021-09-29T17:15:10.568829Z","shell.execute_reply":"2021-09-29T17:15:10.634141Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# callbacks and schedulers\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                                 min_delta=1e-15,\n","                                                 patience=10)\n","\n","reduce_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n","                                                        factor=0.85, \n","                                                        patience=3)\n","\n","callbacks = [early_stopping, reduce_on_plateau]"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:10.637053Z","iopub.execute_input":"2021-09-29T17:15:10.63738Z","iopub.status.idle":"2021-09-29T17:15:10.644027Z","shell.execute_reply.started":"2021-09-29T17:15:10.637339Z","shell.execute_reply":"2021-09-29T17:15:10.642935Z"},"trusted":true}},{"cell_type":"markdown","source":["### Hyperparameters\n","\n","Here goes the paramaters of each model. These can actually be stored in an external JSON file.\n"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["\n","net_params = {\n","    'input_size': len(X_train.columns),\n","    'embedding_size': 128\n","}"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:10.645374Z","iopub.execute_input":"2021-09-29T17:15:10.646175Z","iopub.status.idle":"2021-09-29T17:15:10.661245Z","shell.execute_reply.started":"2021-09-29T17:15:10.646142Z","shell.execute_reply":"2021-09-29T17:15:10.659818Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["gc.collect()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:10.66297Z","iopub.execute_input":"2021-09-29T17:15:10.663223Z","iopub.status.idle":"2021-09-29T17:15:10.875135Z","shell.execute_reply.started":"2021-09-29T17:15:10.663196Z","shell.execute_reply":"2021-09-29T17:15:10.87431Z"},"trusted":true}},{"cell_type":"markdown","source":["### These are model/task dependent parameters"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# external hyperparamaters\n","\n","### fit function hyperparamaters\n","# some models require special paramaters like early stoping in xgboost and lgbm\n","fit_params = {'early_stopping_rounds': 300,\n","                  'verbose': 1000}\n","\n","### application/implementation paramaters\n","# These paramaters are implementation dependent \n","app_params = {'uses_eval_set':True}\n","\n"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:10.876516Z","iopub.execute_input":"2021-09-29T17:15:10.877069Z","iopub.status.idle":"2021-09-29T17:15:10.887997Z","shell.execute_reply.started":"2021-09-29T17:15:10.877036Z","shell.execute_reply":"2021-09-29T17:15:10.887146Z"},"trusted":true}},{"cell_type":"markdown","source":["### Models"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["#with strategy.scope():\n","    \n","# compile all settings in one dictionary, \n","# we can store/load it then to a JSON file\n","model_zoo = {\n","          'LogisticRegression': {\"model\": LogisticRegression, \"main_params\":{}, \"fit_kwargs\":None, \"app_params\": None},\n","          'NetModel': {\"model\": NetModel, \"main_params\":{\"net\": None, \"callbacks\": callbacks}, \"fit_kwargs\":None, \"app_params\": app_params},\n","          # NN models\n","          # we can add any number of models here \n","        }\n","list(model_zoo.keys())"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:10.889481Z","iopub.execute_input":"2021-09-29T17:15:10.890004Z","iopub.status.idle":"2021-09-29T17:15:10.903237Z","shell.execute_reply.started":"2021-09-29T17:15:10.889968Z","shell.execute_reply":"2021-09-29T17:15:10.902074Z"},"trusted":true}},{"cell_type":"markdown","source":["### Stacking\n","\n","Here goes the actual stacking procedure. \n","   - We first define the architecture, and setup the a session.\n","   - Define the stack. That is, the models and transformers in the levels"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# settings: experiment and stacking architecutre\n","\n","# initialize the stack with the actual input\n","X_train_, X_test_ = X_train, X_test\n","\n","transform_pipeline =Pipeline([\n","                            (\"scaler\", QuantileTransformer(output_distribution='normal')),\n","                            (\"biner\", KBinsDiscretizer(n_bins=net_params['embedding_size'], encode='ordinal', strategy='uniform'))])\n","\n","# the n_bins is equal to the embedding size\n","level_1_transformers = [('num', transform_pipeline, numerical_ix)]\n","level_1_transform = ColumnTransformer(transformers=level_1_transformers)\n","\n","\n","# define the actual stack\n","stack = [ {\"level_id\": \"level-1\", \n","           \"models\": [\n","                     'NetModel'\n","                    ],\n","            \"n_folds\": 5,\n","            \"seeds\" : [42, 43, 44, 45],# 46, 47, 48, 49, 50],\n","            \"folder\": \"level_1\", \n","            \"transformer\": level_1_transform,\n","            \"fit_transform_on_test_set\": False,\n","            \"frozen\": False # to freeze the level if already trained\n","            },\n","            \n","         # ...\n","         # we can add any number of levels here\n","         # ...\n","         \n","          {\"level_id\": \"meta_level\",\n","            \"models\": [#'LinearRegression',\n","                       'LogisticRegression'\n","                      ],\n","            \"n_folds\": 5,\n","            \"seeds\" : [42],\n","            \"folder\": \"meta_level\",\n","            \"transformer\": None,\n","            \"fit_transform_on_test_set\": False,\n","            \"frozen\": False\n","          }\n","         \n","         \n","        ]\n","         "],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:10.905427Z","iopub.execute_input":"2021-09-29T17:15:10.906619Z","iopub.status.idle":"2021-09-29T17:15:10.915496Z","shell.execute_reply.started":"2021-09-29T17:15:10.906579Z","shell.execute_reply":"2021-09-29T17:15:10.914814Z"},"trusted":true}},{"cell_type":"markdown","source":["- Loop through each level in the stack"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# create experiment\n","experiments_folder = \"Experiments\"\n","experiment_folder = 'experiement_1' # if None a folder with time stamp will be created\n","experiment_description = \"Simple deep learning model with multiple seeds\"\n","\n","TPS921_experiment = Experiment(title='TPS921',\n","                             description=experiment_description,\n","                             stack=stack,\n","                             model_zoo=model_zoo,\n","                             main_folder=f'{os.getcwd()}{os.sep}{experiments_folder}')\n","\n","TPS921_experiment.join_folder(experiment_folder)\n","\n","\n","results = TPS921_experiment.run(X_train=X_train_.values,\n","                     y=y.values, \n","                     X_test=X_test_.values,\n","                     train_idxs = X_train_.index,\n","                     test_idxs = X_test_.index)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:15:10.916638Z","iopub.execute_input":"2021-09-29T17:15:10.917401Z","iopub.status.idle":"2021-09-29T17:16:40.183148Z","shell.execute_reply.started":"2021-09-29T17:15:10.917363Z","shell.execute_reply":"2021-09-29T17:16:40.180452Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# final results\n","results.head(10)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:16:40.184523Z","iopub.status.idle":"2021-09-29T17:16:40.185222Z","shell.execute_reply.started":"2021-09-29T17:16:40.184998Z","shell.execute_reply":"2021-09-29T17:16:40.185029Z"},"trusted":true}},{"cell_type":"markdown","source":["### Submit the results"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["predictions = results.iloc[:, -1].values"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:16:40.186181Z","iopub.status.idle":"2021-09-29T17:16:40.186825Z","shell.execute_reply.started":"2021-09-29T17:16:40.186613Z","shell.execute_reply":"2021-09-29T17:16:40.18664Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# Save the predictions to a CSV file\n","output = pd.DataFrame({'id': X_test.index,\n","                       'target': predictions})\n","output.to_csv('submission.csv', index=False)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:16:40.188068Z","iopub.status.idle":"2021-09-29T17:16:40.189001Z","shell.execute_reply.started":"2021-09-29T17:16:40.188718Z","shell.execute_reply":"2021-09-29T17:16:40.188747Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# results \n","output.head(20)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-29T17:16:40.190335Z","iopub.status.idle":"2021-09-29T17:16:40.190718Z","shell.execute_reply.started":"2021-09-29T17:16:40.190538Z","shell.execute_reply":"2021-09-29T17:16:40.190554Z"},"trusted":true}}]}