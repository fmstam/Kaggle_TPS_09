{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This notebook describes how to stack a Pytorch simple model for tabular data binary calssification.\n\nIt is part of my solution of the TPS competition in. It will train the same model on different data spilits and then combine the \nout of folds (oofs) in another level using a simple linear regression.\n\nThere are four main components in this notebook used here: **experiment**, **model**, **level**, and **stack**. These will be modeled by classes as described in this notebook.","metadata":{}},{"cell_type":"code","source":"# TPU setup\n!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python3 pytorch-xla-env-setup.py --version 1.7 --apt-packages libomp5 libopenblas-dev\n","metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:58:50.938213Z","iopub.execute_input":"2021-09-28T14:58:50.938528Z","iopub.status.idle":"2021-09-28T14:59:33.805539Z","shell.execute_reply.started":"2021-09-28T14:58:50.938446Z","shell.execute_reply":"2021-09-28T14:59:33.804476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Familiar imports\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\n\nimport os\nimport gc\nimport glob\nimport random\nfrom datetime import datetime\nfrom pathlib import Path\n\n\n\n# helpers\nfrom sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder, PowerTransformer, StandardScaler, \\\n                                  MinMaxScaler, RobustScaler, PolynomialFeatures, QuantileTransformer,  KBinsDiscretizer\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold\nfrom sklearn.pipeline import make_pipeline, Pipeline\n\n\n\n# Models\nfrom sklearn.linear_model import LogisticRegression\n\n\n# torch\nimport torch   \nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchmetrics import AUROC\n\n# for TPU\nimport torch_xla\nimport torch_xla.core.xla_model as xm\n\n# base\nfrom sklearn.base import clone\n\n# scoring\nfrom sklearn import metrics","metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:59:33.814593Z","iopub.execute_input":"2021-09-28T14:59:33.814932Z","iopub.status.idle":"2021-09-28T14:59:35.169206Z","shell.execute_reply.started":"2021-09-28T14:59:33.814891Z","shell.execute_reply":"2021-09-28T14:59:35.168371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# notebook options\npd.set_option(\"display.max_columns\", 100)\npath = \"../input/tabular-playground-series-sep-2021/\"\ntrain_file = \"train.csv\"\ntest_file = \"test.csv\"","metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:59:35.170507Z","iopub.execute_input":"2021-09-28T14:59:35.170727Z","iopub.status.idle":"2021-09-28T14:59:35.175288Z","shell.execute_reply.started":"2021-09-28T14:59:35.170701Z","shell.execute_reply":"2021-09-28T14:59:35.174324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the training data\ntrain = pd.read_csv(f'{path}{os.sep}{train_file}', index_col=0)\ntest = pd.read_csv(f'{path}{os.sep}{test_file}', index_col=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:59:35.178342Z","iopub.execute_input":"2021-09-28T14:59:35.178574Z","iopub.status.idle":"2021-09-28T15:00:07.318563Z","shell.execute_reply.started":"2021-09-28T14:59:35.178548Z","shell.execute_reply":"2021-09-28T15:00:07.317481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Train set size {train.memory_usage(index=False).sum()/(2**30)}')\nprint(f'Test set size {test.memory_usage(index=False).sum()/(2**30)}')","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:00:07.320004Z","iopub.execute_input":"2021-09-28T15:00:07.320389Z","iopub.status.idle":"2021-09-28T15:00:07.342667Z","shell.execute_reply.started":"2021-09-28T15:00:07.320348Z","shell.execute_reply":"2021-09-28T15:00:07.341726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separate target from features\ny = train['claim']\nX = train.drop(['claim'], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:00:07.343932Z","iopub.execute_input":"2021-09-28T15:00:07.344181Z","iopub.status.idle":"2021-09-28T15:00:07.670725Z","shell.execute_reply.started":"2021-09-28T15:00:07.344154Z","shell.execute_reply":"2021-09-28T15:00:07.669647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"\n# identify columns\nnumerical_cols = list(X.select_dtypes(include=np.number).columns)\nnon_numeric_cols = list(X.select_dtypes(include=['object', 'bool']).columns)\n\nprint(f'We have {len(numerical_cols)} numeric and {len(non_numeric_cols)} non-numeric features')\n\n\n# work on a copy\nX_train = X.copy()\nX_test = test.copy()\n\n\n# all features\nfeatures = non_numeric_cols + numerical_cols\n\n# new features\n# https://www.kaggle.com/hiro5299834/tps-sep-2021-single-lgbm\nX_train['n_missing'] = X_train[features].isna().sum(axis=1)\nX_test['n_missing'] = X_test[features].isna().sum(axis=1)\n\nX_train['std'] = X_train[features].std(axis=1)\nX_test['std'] = X_test[features].std(axis=1)\n\n#X_train['min'] = X_train[features].min(axis=1)\n#X_test['min'] = X_test[features].min(axis=1)\n\nfeatures += ['n_missing', 'std']\n#n_missing = X_train['n_missing'].copy()\n\n# imputation\nX_train[features] = X_train[features].fillna(X_train[features].mean())\nX_test[features] = X_test[features].fillna(X_test[features].mean())\n\nscaler = StandardScaler()\nX_train[features] = scaler.fit_transform(X_train[features])\nX_test[features] = scaler.transform(X_test[features])\n\n\n# useful for column transformers \nnumerical_ix = X_train.columns.get_indexer(features)\n#non_numeric_ix = X_train.columns.get_indexer(non_numeric_cols)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:00:07.672164Z","iopub.execute_input":"2021-09-28T15:00:07.672425Z","iopub.status.idle":"2021-09-28T15:00:18.802617Z","shell.execute_reply.started":"2021-09-28T15:00:07.672387Z","shell.execute_reply":"2021-09-28T15:00:18.801748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model-dev helper functions\n\nThese are functions to save and load predictions, they can be wrapped within a class for a better modeling or kept as they are since they are independent of the project setting.\n","metadata":{}},{"cell_type":"code","source":"\n## helper fucntions\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\n        \ndef to_file(data, output_folder, idxs=None, suffix='.csv'):\n    print(data)\n    df = pd.DataFrame(data)\n    df.to_csv(f'{output_folder}{os.sep}{suffix}', index=True)\n        \n    \ndef calc_folds_indexes(X, y, n_folds=5, shuffle=True, sampler=KFold, seeds=[42]):\n    \"\"\"\n    Create folds from a dataset X and a target y\n    sampler: can be KFold,  StratifiedKFold, or any sampling class  \n    \n    return a list of dictionaries of {'seed':, 'idxs':[train_idxs, test_idxs]}\n    \"\"\"\n    folds_idxs_list = []\n    for seed in seeds:\n        folds = sampler(n_splits=n_folds, \n                        random_state=seed,\n                        shuffle=shuffle)\n\n        folds_idxs_list.append({'seed': seed, 'idxs':list(folds.split(X, y))})\n        \n    return folds_idxs_list   \n\ndef score(y, target, average=False):\n    # if y is a list then it will return a list of scores\n    # if average is True then it will return the mean of the scores\n    \n    if type(y) in [list, np.ndarray]:\n        scores = []\n        for y_i in y:\n            scores.append(score_func(y_i, target, **score_func_params))\n        if average:\n            return np.mean(scores)\n        else:\n            return scores\n        \n    return score_func(y, target, **score_func_param)\n","metadata":{"code_folding":[],"execution":{"iopub.status.busy":"2021-09-28T15:00:18.804313Z","iopub.execute_input":"2021-09-28T15:00:18.804628Z","iopub.status.idle":"2021-09-28T15:00:18.819702Z","shell.execute_reply.started":"2021-09-28T15:00:18.804588Z","shell.execute_reply":"2021-09-28T15:00:18.818821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initialize things\n\n# seed\nseed = 42\nseed_everything(seed)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:00:18.820834Z","iopub.execute_input":"2021-09-28T15:00:18.82115Z","iopub.status.idle":"2021-09-28T15:00:18.83802Z","shell.execute_reply.started":"2021-09-28T15:00:18.821062Z","shell.execute_reply":"2021-09-28T15:00:18.837113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ModelWrapper \nThis main role of this class is to avoid coding multiple classes for each model (or model types). We can see that models can actually be categorized into different categories, where some models accept more parameters than the others. For instance xgboost can use an evaluation set to determine the stopping round number, while Lasso does not have such extra parameters.\n\nThanks to the flexibility of Python and the design of the base models, we can wrap the model and develope a `wrapper` to do what the model should do. In fact, we can easily stretch this class to support sklearn pipelines or any framework we are using. The idea is again, seperate code from data and try to generalize.\n","metadata":{}},{"cell_type":"code","source":"class ModelWrapper():\n    def __init__(self, \n                 model,\n                 name,\n                 main_params,\n                 uses_eval_set=False,\n                 fit_params={}):\n        \n        self.model = model\n        self.name = name\n        self.main_params = main_params\n        self.uses_eval_set = uses_eval_set\n        self.fit_params = fit_params # any extra params for the 'fit' function\n                \n    def create_model(self, random_state=None):\n        \"\"\"\n        create a model\n        \"\"\"\n        model = self.model(**self.main_params)\n        if random_state is not None:\n            if hasattr(model, 'random_state'):\n                model.random_state = random_state\n            elif hasattr(model, 'random_seed'):\n                model.random_seed = random_state\n        \n        return model\n    \n        ","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:00:18.839216Z","iopub.execute_input":"2021-09-28T15:00:18.839457Z","iopub.status.idle":"2021-09-28T15:00:18.849785Z","shell.execute_reply.started":"2021-09-28T15:00:18.839432Z","shell.execute_reply":"2021-09-28T15:00:18.849005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ModelTrainer\nThis role of this class is to train a model and calculate the oofs and the test predictions (meta-features). That is, to cross validate.\n","metadata":{}},{"cell_type":"code","source":"class ModelTrainer():\n    def __init__(self,\n                  model_wrapper: ModelWrapper):\n        \n        self.modelwrapper = model_wrapper\n        \n    def cross_validate(self,\n                  X, y,\n                  X_test,\n                  folds_idxs,\n                  transformer=None,\n                  fit_transform_on_test_set=False,\n                  verbose=False,\n                  use_different_random_states=True, \n                  score_function=metrics.roc_auc_score,\n                  score_function_params={}):\n        \"\"\"\n        Return the oofs predictions and the meta features (test predictions)\n        \"\"\"\n        \n        test_predictions = 0\n        oof_predictions = np.zeros_like(np.array(y), dtype=np.float64)\n        valid_mean_score = [] \n        for fold, (train_ix, valid_ix) in enumerate(folds_idxs): # we are not using spilit here for a better generalization\n            X_train, X_valid = X[train_ix], X[valid_ix]\n            y_train, y_valid = y[train_ix], y[valid_ix]\n                             \n            # transform input\n            if transformer is not None:\n                X_train = transformer.fit_transform(X_train)\n                if fit_transform_on_test_set:\n                    X_valid = transformer.fit_transform(X_valid)\n                    X_test_ = transformer.fit_transform(X_test)\n                else:\n                    X_test_ = transformer.transform(X_test)\n                    X_valid = transformer.transform(X_valid)\n            else:\n                X_test_ = X_test\n                \n            # check if we train each fold on differently initialized clone\n            if use_different_random_states:\n                model = self.modelwrapper.create_model(random_state=fold)\n            else:\n                model = self.modelwrapper.create_model()\n            \n            # fit the model\n            if self.modelwrapper.uses_eval_set:\n                model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], **self.modelwrapper.fit_params)\n            else:\n                model.fit(X_train, y_train, **self.modelwrapper.fit_params)\n                \n            ## predictions\n            # on the validation set\n            valid_predications = model.predict_proba(X_valid)[:, -1]\n            score = score_function(y_valid, valid_predications)\n            valid_mean_score.append(score)\n            oof_predictions[valid_ix] = valid_predications\n            \n            # on the test set        \n            test_predictions += model.predict_proba(X_test_)[:, -1] / len(folds_idxs)\n            \n            if verbose:\n                print('Model:{} Fold:{} score:{:.4f}'.format(self.modelwrapper.name, fold + 1, score))\n        \n        if verbose:\n            print('Average score:{:.4f} ({:.4f})'.format(np.mean(valid_mean_score), np.std(valid_mean_score) ))\n    \n        return oof_predictions, test_predictions","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:00:18.851376Z","iopub.execute_input":"2021-09-28T15:00:18.851917Z","iopub.status.idle":"2021-09-28T15:00:18.874919Z","shell.execute_reply.started":"2021-09-28T15:00:18.851876Z","shell.execute_reply":"2021-09-28T15:00:18.873913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Level\nThe level class glues all components in a given layer","metadata":{}},{"cell_type":"code","source":"class Level():\n    def __init__(self,\n                level_id,\n                models,\n                folder,\n                transformer,\n                n_folds=5,\n                seeds=[42],\n                frozen=False,\n                fit_transform_on_test_set = False,\n                use_different_random_states=True):\n        \n        self.level_id = level_id\n        self.models = models\n        self.folder = folder\n        self.transformer = transformer\n        self.n_folds = n_folds\n        self.seeds = seeds\n        self.frozen = frozen=False\n        self.fit_transform_on_test_set = fit_transform_on_test_set\n        self.use_different_random_states = use_different_random_states\n    \n    def create(self, model_zoo):\n        \"\"\"\n         Create a level.\n         model_zoo: a dictionay of all avialable models.\n        \"\"\"\n        self.model_wrappers = []\n        \n        # get models \n        # if models is set to 'all' use all models\n        if self.models[0].lower() == 'all':\n            level_models_names = model_zoo.keys()\n        else: \n            level_models_names = self.models\n\n        for model_name in level_models_names:\n            # get paramaters  \n            model_dict = model_zoo[model_name]\n            model = model_dict['model']\n            fit_kwargs = model_dict['fit_kwargs']\n            app_params = model_dict['app_params']\n            main_params = model_dict['main_params']\n\n            model_wrapper = ModelWrapper(model=model, name=model_name, main_params=main_params)\n            if fit_kwargs is not None:\n                model_wrapper.fit_params = fit_kwargs\n            if app_params is not None:\n                model_wrapper.uses_eval_set = app_params['uses_eval_set']\n            self.model_wrappers.append(model_wrapper)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:00:18.876623Z","iopub.execute_input":"2021-09-28T15:00:18.876981Z","iopub.status.idle":"2021-09-28T15:00:18.892664Z","shell.execute_reply.started":"2021-09-28T15:00:18.876926Z","shell.execute_reply":"2021-09-28T15:00:18.89143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Level Trainer\nTrains all models in a given level.","metadata":{}},{"cell_type":"code","source":"class LevelTrainer():\n    def __init__(self,\n                level,\n                seeds_folds_idxs_list):\n        self.level = level\n        self.seeds_folds_idxs_list = seeds_folds_idxs_list\n        \n    def train(self, X_train, y, X_test, verbose=True, agg_func=None):\n        \"\"\"\n        train the level and return the oofs and meta-features for each model in the level.\n        If the level has many seeds it will either use the agg_func to combine predictions\n        or will just return eveything, it depends on agg_func\n        \n        agg_func: can be None, np.mean, or any other numpy reduction function\n        \"\"\"\n\n        level_oof_preds, level_test_preds = {}, {}\n        for model_wrapper in self.level.model_wrappers:\n            if verbose:\n                print('-'*30)\n                print(f'Model:{model_wrapper.name}')\n                print('-'*30)\n\n            # train each model with as many times as the length of folds_idxs_list \n            model_oof_preds, model_test_preds = [], []\n            \n            for seeds_folds_idxs in self.seeds_folds_idxs_list:\n                seed, folds_idxs = seeds_folds_idxs['seed'], seeds_folds_idxs['idxs']\n                print('-'*30)\n                print(f'Seed:{seed}')\n                print('-'*30)\n                \n                trainer = ModelTrainer(model_wrapper)\n                oof_preds, test_preds = trainer.cross_validate(X_train, \n                                                          y,\n                                                          X_test,\n                                                          transformer=self.level.transformer,\n                                                          folds_idxs=folds_idxs,\n                                                          verbose=verbose,\n                                                          fit_transform_on_test_set=self.level.fit_transform_on_test_set)\n                if agg_func is None:\n                    level_oof_preds[f'{model_wrapper.name}_seed_{seed}'] =  oof_preds\n                    level_test_preds[f'{model_wrapper.name}_seed_{seed}'] =  test_preds\n                else: # collect them in order to aggregate them with the agg_func function\n                    model_oof_preds.append(oof_preds)\n                    model_test_preds.append(test_preds)\n\n          # aggregate the results\n        if agg_func is not None:\n            level_oof_preds[f'{model_wrapper.name}'] = agg_func(np.column_stack(model_oof_preds))\n            level_test_preds[f'{model_wrapper.name}'] = agg_func(np.column_stack(model_test_preds))\n\n        if verbose:\n            print('-'*30)\n\n        return pd.DataFrame(level_oof_preds), pd.DataFrame(level_test_preds)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:00:18.897685Z","iopub.execute_input":"2021-09-28T15:00:18.898106Z","iopub.status.idle":"2021-09-28T15:00:18.913576Z","shell.execute_reply.started":"2021-09-28T15:00:18.898025Z","shell.execute_reply":"2021-09-28T15:00:18.91259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Experiment \nSince in many cases everything boils down to stacking, the experiment class will handle the organization of the resulted files from the test: test and oofs predictions. Therefore, assuming the project has the following structure with a folder called **experiments** we can save our tests in this folder. This is what this class will do. This class is the entry point for any run (experiment) in the project. It reads the input and the settings and produces the output.\n\n```\n    TPS_project\n    │   README.md\n    │\n    └───notebooks\n    │   ...\n    │\n    └───experiments\n    │   │   \n    │   │\n    │   └───experiment_1   \n    │   │   level_1_oofs.csv\n    │   │   level_1_test.csv\n    │   │   level_2_oofs.csv\n    │   │   level_2_test.csv\n    │   │   ...\n    │   │   meta_level_oofs.csv\n    │   │   meta_level_test.csv\n    │   └───experiment_...\n```\n\n\n>The code that generated the results is important to save too, but that can be done easily by creating a new version of the notebook or copying notebook with the CV_LB results. If we are running it in a local machine without notebooks, we can create a small function to copy the code files to the experiment levels. On other words, to save the code and the results for each experiement for a better look up.\n\n>This class is so important when running notebooks in our computers. Since Kaggle has a nice notebook management system it saves outputs as well.\n\n","metadata":{}},{"cell_type":"code","source":"class Experiment():\n    def __init__(self,\n                 title,\n                 description,\n                 stack,\n                 model_zoo,\n                 main_folder=os.getcwd()):\n        \n        self.title = title\n        self.main_folder = main_folder\n        self.stack = stack\n        self.model_zoo = model_zoo\n        self.description = description\n        # create the main folder if it does not exist\n        if not os.path.exists(f'{self.main_folder}'):\n            os.makedirs(f'{self.main_folder}', exist_ok=True)\n        \n    def join_folder(self, folder=None):\n         \"\"\"\n         Join a folder and output where results will be saved.\n         If 'folder' is None, it will create a folder\n         with a time stamp.\n         \"\"\"\n\n         # create time stamp and subfolder with the current time stamp\n         if folder is not None: # if folder is specified\n            self.output_folder = folder \n            # create a folder if does not exit.\n            folder_path = f'{self.main_folder}{os.sep}{self.output_folder}'\n            if not os.path.exists(folder_path):\n                os.makedirs(folder_path)                \n         else: # create a folder with the time stamp\n            time_stamp = datetime.now().isoformat(' ', 'seconds')\n            self.output_folder = self.title + ' ' + time_stamp.replace(':', '-')\n            # create and replace if it exits.\n            Path(f'{self.main_folder}{os.sep}{self.output_folder}').mkdir(parents=True, exist_ok=True)\n    \n    \n    def run(self, X_train, y, X_test, \n            train_idxs,\n            test_idxs,\n            verbose=True, store=True):\n        \n        # run the stack\n        for  level_params in self.stack:\n            # create all models in the level\n            level = Level(**level_params)\n            level.create(self.model_zoo)\n\n            print('-'*50)\n            print(f'Current Level: {level.level_id}')\n            print('-'*50)\n\n            # join the level's output folder\n            #self.join_folder(folder=level.folder)\n\n            # create folds indexes for the level\n            seeds_folds_idxs_list = calc_folds_indexes(X=X_train,\n                                                       y=y,\n                                                       n_folds=level.n_folds,\n                                                       sampler=StratifiedKFold,\n                                                       seeds=level.seeds)\n\n            # train the level\n            if not level.frozen:  # escape any trained level   \n                level_trainer = LevelTrainer(level=level, \n                                             seeds_folds_idxs_list=seeds_folds_idxs_list)\n\n                level_oof_preds, level_test_preds =  level_trainer.train(X_train=X_train,\n                                                                         y=y,\n                                                                         X_test=X_test)\n                # store predictions?\n                if store:\n                    # oofs \n                    level_oof_preds.to_csv(f'{self.main_folder}{os.sep}{self.output_folder}{os.sep}{level.level_id}_oofs.csv')\n                    # test predictions\n                    level_test_preds.to_csv(f'{self.main_folder}{os.sep}{self.output_folder}{os.sep}{level.level_id}_test.csv')\n                    \n                \n                # update train and test \n                X_train, X_test = level_oof_preds.values, level_test_preds.values\n            else:\n                print('This level is already trained')\n                # load saved of this level and raise error\n                fold_id = level.n_folds\n                folder =f'{self.main_folder}{os.sep}{self.output_folder}'\n                \n                # new features \n                level_oof_preds = pd.read_csv(f\"{folder}{os.sep}*{fold_id}_oofs.csv\")\n                level_test_preds = pdf.read_csv(f\"{folder}{os.sep}*{fold_id}_test.csv\")\n                \n                X_train = level_oof_preds.values\n                X_test = level_test_preds.values\n                \n            if verbose:\n                display(level_oof_preds.head(10))\n                display(level_test_preds.head(10))\n                \n        # return the last output from the last level\n        return level_test_preds","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:00:18.91472Z","iopub.execute_input":"2021-09-28T15:00:18.915662Z","iopub.status.idle":"2021-09-28T15:00:18.934703Z","shell.execute_reply.started":"2021-09-28T15:00:18.915628Z","shell.execute_reply":"2021-09-28T15:00:18.933634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DNN Models","metadata":{}},{"cell_type":"code","source":"# My other nets here: https://github.com/fmstam/MLS/blob/master/ceot_drl/core/DNN.py\nclass Net(nn.Module):\n    def __init__(self,\n                  input_size, \n                  output_size=1, \n                  embedding_layer=nn.Embedding, # nn.Embedding, nn.Linear, nn.Conv1d, ...\n                  embedding_size=64,\n                  feature_size=16\n                 ):\n            \n        super(Net, self).__init__()\n        \n        self.input_size = input_size\n        self.embedding_size = embedding_size\n        self.output_shape= output_size\n        self.feature_size = feature_size\n        \n        \n        # create the net\n        self.embedding_layer = embedding_layer(embedding_size, feature_size)\n        # first  layer\n        self.fc_1 = nn.Linear(in_features=input_size * feature_size, out_features=feature_size)\n        self.dropout_1 = nn.Dropout(0.6)\n        #self.batch_norm1d = nn.BatchNorm1d(feature_size)\n        # second layer\n        self.fc_2 = nn.Linear(in_features=feature_size, out_features=int(feature_size/2))\n        self.dropout_2 = nn.Dropout(0.4)\n        # third layer\n        self.fc_3 = nn.Linear(in_features=int(feature_size/2), out_features=int(feature_size/4))\n        self.dropout_3 = nn.Dropout(0.2)\n        # output\n        self.fc_out = nn.Linear(in_features=int(feature_size/4), out_features=output_size)\n        \n        \n    \n    def forward(self, x):\n        if isinstance(x, torch.Tensor):\n            x = x\n        else:\n            x = torch.Tensor(x)\n\n        \n        x = self.embedding_layer(x.long())\n        x = x.view(x.shape[0], self.input_size * self.feature_size)\n        \n        x = F.silu(self.fc_1(x))\n        x = self.dropout_1(x)\n        #x = self.batch_norm1d(x)    \n        \n        x = F.silu(self.fc_2(x)) # silu = swish function\n        x = self.dropout_2(x)\n        \n        x = F.silu(self.fc_3(x)) # silu = swish function\n        x = self.dropout_3(x)\n        \n        \n        x = self.fc_out(x)\n        x = torch.sigmoid(x)        \n        return x    \n\n\nclass CompDataSet(Dataset):\n    def __init__(self, X, y, transformer):\n        \n        self.X = X\n        self.y = y\n        self.transformer = transformer\n        \n    def __getitem__(self, index):\n        x = self.X[index]\n        y = self.y[index]\n        \n        if self.transformer:\n            x = self.transformer(x)\n        \n        return x, y\n    \n    def __len__(self):\n        return len(self.X)\n    \n\n    \nclass NetModel():\n    def __init__(self,\n                 net,\n                 optimizer=torch.optim.Adam,\n                 lr=2.5e-4,\n                 loss=torch.nn.BCELoss(),\n                 metric=AUROC(),\n                 batch_size=1024,\n                 scheduler=torch.optim.lr_scheduler.OneCycleLR,\n                 max_lr=1e-3, \n                 device='gpu'\n                 ):\n        \n        self.net = net\n        self.optimizer = optimizer(self.net.parameters(), lr)\n        self.lr = lr\n        self.max_lr = max_lr\n        self.loss = loss\n        self.metric = metric\n        self.batch_size = batch_size\n        self.batch_size = batch_size\n        self.scheduler = scheduler\n        \n        self.device = 'cpu'\n        if device is 'gpu':\n            if torch.cuda.is_available():\n                self.device = 'cuda:0'\n        elif device is 'tpu':\n            self.device = xm.xla_device()\n            \n                \n        self.best_model = None\n    \n    def fit(self, X, y, eval_set=None, epochs=1, verbose=1, plot_loss=True):\n        \n        X_train_dataset = CompDataSet(X, y, transformer=torch.tensor)\n        X_train_dataloader = DataLoader(X_train_dataset, batch_size=self.batch_size)\n        \n        if eval_set is not None:\n            # use the last item in the eval_set for validation\n            X_valid_dataset = CompDataSet(eval_set[-1][0], eval_set[-1][1], transformer=torch.tensor)\n            X_valid_dataloader = DataLoader(X_valid_dataset, batch_size=self.batch_size)\n\n            \n        best_train_score = - float('inf')\n        best_valid_score = - float('inf')\n        ## actual training loop\n        # put model to the selected device\n        self.net.to(self.device)\n        gc.collect() # clearn up before the loop\n        n_batches = len(X_train_dataloader) # number of batches (steps)\n        # update the scheudaler number of steps according to the batches \n        self.scheduler = self.scheduler(self.optimizer, max_lr=self.max_lr, epochs=epochs, steps_per_epoch=n_batches)\n        \n        if verbose > 0:\n            print('Start of training ...')\n        # epochs\n        for epoch in range(epochs):        \n            # tracking the train and validation losses\n            train_loss_list = []\n            valid_loss_list = []\n        \n            # put model in training mode\n            self.net.train()\n            # rest the metric\n            self.metric.reset()\n            epoch_mean_loss = 0\n            \n            for batch_X_train, batch_y_train in X_train_dataloader:\n                \n                # forward step\n                y_predict = self.net(batch_X_train.to(self.device))\n                batch_y_train = torch.unsqueeze(batch_y_train.float(), axis=1).to(self.device)\n                \n                # backward step\n                self.optimizer.zero_grad() # zero gradds because pytorch accumaltes them before each batch\n\n                loss = self.loss(y_predict, batch_y_train)\n                \n                loss.backward() # backpropagate error\n                self.optimizer.step() # update weights\n                self.scheduler.step() # update the LR schedualer\n                epoch_mean_loss += (loss.detach().cpu().item()) / n_batches # store loss\n                self.metric(y_predict, batch_y_train.int()) # calculate metric for the batch target hast to be int\n                \n            train_score = self.metric.compute()\n            if train_score > best_train_score:\n                best_train_score = train_score\n                # time to checkpoint the model based on training set\n                #torch.save(self.net.state_dict(), 'best_model.pt')\n                self.best_model = self.net.state_dict()\n\n                \n            # evaluation set?\n            if eval_set is not None:    \n                # put model in validation mode\n                self.net.eval()\n                # rest the metric\n                self.metric.reset() \n                \n                with torch.no_grad(): # stop autograd engine\n                    for batch_X_train, batch_y_train in X_valid_dataloader:\n                        y_predict = self.net(batch_X_train.to(self.device))\n                        batch_y_train = torch.unsqueeze(batch_y_train.float(), axis=1).to(self.device)\n                        self.metric(y_predict, batch_y_train.int())\n                        \n                     # calculate metric for the batch target hast to be int\n                    valid_score = self.metric.compute()\n                    if valid_score > best_valid_score:\n                        best_valid_score = valid_score \n                        # time to checkpoint the model based on the eval set\n                        # torch.save(self.net.state_dict(), 'best_model.pt')\n                        self.best_model = self.net.state_dict()\n\n                    print(f'Epoch {epoch}/{epochs}: loss {epoch_mean_loss} train_score {train_score} best_score {best_train_score} valid_score {valid_score} best_score {best_valid_score}')\n                    \n            else: # no eval-set was provided use the training set only\n                print(f'Epoch {epoch}/{epochs}: loss {epoch_mean_loss} train_score {train_score} best_score {best_train_score}')\n\n            train_loss_list.append(epoch_mean_loss)\n            \n        # clean up\n        del X_train_dataloader\n        del X_valid_dataloader\n        gc.collect()\n            \n            \n        return self\n\n    def predict_proba(self, X):\n        if not isinstance(X, torch.Tensor):\n            X = torch.Tensor(X)\n            \n        X = X.to(self.device)\n        \n        print(X.shape)\n        # use the best model for predition\n        assert self.best_model is not None, \"The model is not trained yet\"\n        self.net.load_state_dict(self.best_model)\n        X =  self.net(X).detach().cpu().numpy()\n        \n        return X\n        \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:00:18.936506Z","iopub.execute_input":"2021-09-28T15:00:18.936963Z","iopub.status.idle":"2021-09-28T15:00:27.515958Z","shell.execute_reply.started":"2021-09-28T15:00:18.936913Z","shell.execute_reply":"2021-09-28T15:00:27.514676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameters\n\nHere goes the paramaters of each model. These can actually be stored in an external JSON file.\n","metadata":{}},{"cell_type":"code","source":"net_params = {\n    'input_size': len(X_train.columns),\n    'embedding_size': 100,\n    'feature_size': 64\n}","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:00:27.517891Z","iopub.execute_input":"2021-09-28T15:00:27.518234Z","iopub.status.idle":"2021-09-28T15:00:27.524514Z","shell.execute_reply.started":"2021-09-28T15:00:27.518189Z","shell.execute_reply":"2021-09-28T15:00:27.523601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:00:27.526608Z","iopub.execute_input":"2021-09-28T15:00:27.528326Z","iopub.status.idle":"2021-09-28T15:00:27.730241Z","shell.execute_reply.started":"2021-09-28T15:00:27.528277Z","shell.execute_reply":"2021-09-28T15:00:27.72912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### These are model/task dependent parameters","metadata":{}},{"cell_type":"code","source":"# external hyperparamaters\n\n### fit function hyperparamaters\n# some models require special paramaters like early stoping in xgboost and lgbm\nfit_params = {'early_stopping_rounds': 300,\n                  'verbose': 1000}\n\nnet_fit_params = {'epochs': 5}\n\n### application/implementation paramaters\n# These paramaters are implementation dependent \napp_params = {'uses_eval_set':True}\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:00:27.732122Z","iopub.execute_input":"2021-09-28T15:00:27.732451Z","iopub.status.idle":"2021-09-28T15:00:27.741953Z","shell.execute_reply.started":"2021-09-28T15:00:27.732409Z","shell.execute_reply":"2021-09-28T15:00:27.740865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Models","metadata":{}},{"cell_type":"code","source":"# compile all settings in one dictionary, \n# we can store/load it then to a JSON file\nmodel_zoo = {\n          'LogisticRegression': {\"model\": LogisticRegression, \"main_params\":{}, \"fit_kwargs\":None, \"app_params\": None},\n          'NetModel': {\"model\": NetModel, \"main_params\":{\"net\": Net(**net_params), \"device\":\"tpu\"}, \"fit_kwargs\":net_fit_params, \"app_params\": app_params},\n          # NN models\n          #'TabNetClassifier': {\"model\": tabnet_clf, \"fit_kwargs\":tabnet_fit_params, \"app_params\": app_params},\n          # we can add any number of models here \n        }\nlist(model_zoo.keys())","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:00:27.743489Z","iopub.execute_input":"2021-09-28T15:00:27.743802Z","iopub.status.idle":"2021-09-28T15:00:27.763856Z","shell.execute_reply.started":"2021-09-28T15:00:27.743763Z","shell.execute_reply":"2021-09-28T15:00:27.762859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stacking\n\nHere goes the actual stacking procedure. \n   - We first define the architecture, and setup the a session.\n   - Define the stack. That is, the models and transformers in the levels","metadata":{}},{"cell_type":"code","source":"# settings: experiment and stacking architecutre\n\n# initialize the stack with the actual input\nX_train_, X_test_ = X_train, X_test\n\n\ntransform_pipeline =Pipeline([\n                            (\"scaler\", QuantileTransformer(output_distribution='normal')),\n                            (\"biner\", KBinsDiscretizer(n_bins=net_params['embedding_size'], encode='ordinal', strategy='uniform'))])\n\n# the n_bins is equal to the embedding size\nlevel_1_transformers = [('num', transform_pipeline, numerical_ix)]\nlevel_1_transform = ColumnTransformer(transformers=level_1_transformers)\n\n\n# define the actual stack\nstack = [ {\"level_id\": \"level-1\", \n           \"models\": [\n                     'NetModel'\n                    ],\n            \"n_folds\": 5,\n            \"seeds\" : [42],# 43, 44, 45, 46, 47, 48, 49, 50],\n            \"folder\": \"level_1\", \n            \"transformer\": level_1_transform,\n            \"fit_transform_on_test_set\": False,\n            \"frozen\": False # to freeze the level if already trained\n            },\n            \n         # ...\n         # we can add any number of levels here\n         # ...\n         \n          {\"level_id\": \"meta_level\",\n            \"models\": [#'LinearRegression',\n                       'LogisticRegression'\n                      ],\n            \"n_folds\": 5,\n            \"seeds\" : [42],\n            \"folder\": \"meta_level\",\n            \"transformer\": None,\n            \"fit_transform_on_test_set\": False,\n            \"frozen\": False\n          }\n         \n         \n        ]\n         ","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:00:27.765732Z","iopub.execute_input":"2021-09-28T15:00:27.766112Z","iopub.status.idle":"2021-09-28T15:00:27.77916Z","shell.execute_reply.started":"2021-09-28T15:00:27.766051Z","shell.execute_reply":"2021-09-28T15:00:27.77819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Loop through each level in the stack","metadata":{}},{"cell_type":"code","source":"# create experiment\nexperiments_folder = \"Experiments\"\nexperiment_folder = 'experiement_1' # if None a folder with time stamp will be created\nexperiment_description = \"Simple net model with multiple seeds\"\n\nTPS921_experiment = Experiment(title='TPS-9-21',\n                             description=experiment_description,\n                             stack=stack,\n                             model_zoo=model_zoo,\n                             main_folder=f'{os.getcwd()}{os.sep}{experiments_folder}')\n\nTPS921_experiment.join_folder(experiment_folder)\n\nresults = TPS921_experiment.run(X_train=X_train_.values,\n                     y=y.values, \n                     X_test=X_test_.values,\n                     train_idxs = X_train_.index,\n                     test_idxs = X_test_.index)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:00:27.781006Z","iopub.execute_input":"2021-09-28T15:00:27.781297Z","iopub.status.idle":"2021-09-28T15:01:40.528345Z","shell.execute_reply.started":"2021-09-28T15:00:27.781269Z","shell.execute_reply":"2021-09-28T15:01:40.527012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final results\nresults.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:01:40.529722Z","iopub.status.idle":"2021-09-28T15:01:40.530443Z","shell.execute_reply.started":"2021-09-28T15:01:40.530151Z","shell.execute_reply":"2021-09-28T15:01:40.530177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submit the results","metadata":{}},{"cell_type":"code","source":"predictions = results.iloc[:, -1].values","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:01:40.531787Z","iopub.status.idle":"2021-09-28T15:01:40.532457Z","shell.execute_reply.started":"2021-09-28T15:01:40.532185Z","shell.execute_reply":"2021-09-28T15:01:40.532209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the predictions to a CSV file\noutput = pd.DataFrame({'id': X_test.index,\n                       'target': predictions})\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:01:40.533739Z","iopub.status.idle":"2021-09-28T15:01:40.534401Z","shell.execute_reply.started":"2021-09-28T15:01:40.53412Z","shell.execute_reply":"2021-09-28T15:01:40.534145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# results \noutput.head(20)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T15:01:40.535702Z","iopub.status.idle":"2021-09-28T15:01:40.536514Z","shell.execute_reply.started":"2021-09-28T15:01:40.53624Z","shell.execute_reply":"2021-09-28T15:01:40.536267Z"},"trusted":true},"execution_count":null,"outputs":[]}]}